{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cebac8e8-d093-4640-8b05-12ac1a944c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# import optuna\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d26f6095-c187-4ef3-8c9f-4cb56bed0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data_funs import load_data, gen_batch_data_fixations_choice, gen_batch_data_fixations_only, gen_batch_data_choice_only\n",
    "from train_and_test_funs import test, train_on_simulation_then_human_with_intermediate_tests, test_record_each_output, compute_heldout_performance\n",
    "from neural_nets import SimpleLSTM, SimpleMLP, SimpleGRU, SimpleTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebcb002-d625-4151-b66e-23a9ca5bf1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MLP'\n",
    "train_seq_part = 'choice_only'\n",
    "n_simulation_sequences_train = 1e3\n",
    "n_simulation_sequences_train = 1e3\n",
    "n_human_sequences_train = 0\n",
    "n_sequences_test = 500\n",
    "n_sequences_final_performance = 500\n",
    "d_model = 128\n",
    "n_layers = 2\n",
    "n_head = 2\n",
    "sim_lr = .001\n",
    "human_lr = .001\n",
    "batch_size = 32\n",
    "dropout = 0\n",
    "run_idx = 0\n",
    "on_cluster = True\n",
    "test_batch_increment_sim = 200\n",
    "test_batch_increment_human = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c8c58a-1d7f-4b44-a8a1-b459b2b033fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(n_simulation_sequences_train))\n",
    "\n",
    "####################################################\n",
    "#### Set cluster folders\n",
    "#############################################\n",
    "# set path to the human and simulation data\n",
    "if on_cluster:\n",
    "    sim_data_path = '/scratch/gpfs/erussek/RNN_project/optimal_fixation_sims'\n",
    "    human_data_path = '/scratch/gpfs/erussek/RNN_project/human_trials.json'\n",
    "else:\n",
    "    sim_data_path = '/Users/erussek/Dropbox/Griffiths_Lab_Stuff/Data/RNNs/optimal_fixation_sims'\n",
    "    human_data_path = '/Users/erussek/Dropbox/Griffiths_Lab_Stuff/Data/RNNs/human_trials.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e93b0b7-f272-4072-b64d-5b9d055986ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, for choice only - want the input to just have chosen vs unchosen... \n",
    "train_data_sim, val_data_sim, test_data_sim, train_data_human, val_data_human, test_data_human = load_data(sim_data_path, human_data_path,this_seed=run_idx,split_human_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed0b2f8f-0ce1-47ed-b785-389e764897f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "batch_idx = 3\n",
    "data = train_data_human\n",
    "use_human_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56ac6a86-9c78-422c-9d69-3cfc591ad291",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sim_data = data[batch_idx*batch_size:((batch_idx+1)*(batch_size))]\n",
    "batch_choices_idx = [trial_data['choice'] - 1 for trial_data in batch_sim_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25361ea8-10b5-4c6a-b394-18fcfabc7383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_choices_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b7ffd66f-511c-4712-a8ba-a78052c45903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleChoiceOnly(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_output = nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        o = torch.zeros(x.shape)\n",
    "        for item in range(3):\n",
    "            \n",
    "            a = torch.zeros(x.shape[0],1)\n",
    "            a[:,0] = x[:,item]\n",
    "            o[:,item] = torch.squeeze(input_output(a))\n",
    "\n",
    "        return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b467c89a-8273-4e50-b12a-a0bd70f189c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Functions to generate data\n",
    "    gen_data_func_by_train_seq_part = {\"fix_and_choice\": gen_batch_data_fixations_choice, \"fix_only\": gen_batch_data_fixations_only, \"choice_only\": gen_batch_data_choice_only, \"choice_then_fix\": gen_batch_data_choice_only}\n",
    "    gen_data_func_pre = gen_data_func_by_train_seq_part[train_seq_part]\n",
    "    # set the fix unit\n",
    "    gen_data_func = lambda a, b, c, use_human_data=False : gen_data_func_pre(a, b, c, fix_unit = fix_unit, use_human_data = use_human_data)\n",
    "    \n",
    "    fix_unit = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "47cfdd6b-003e-4610-a24f-73370b3eeb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Training on simulated data\n",
      "Training on human data\n"
     ]
    }
   ],
   "source": [
    "model = SimpleChoiceOnly()\n",
    "    # non neural net training parameters\n",
    "criterion   = torch.nn.MSELoss()\n",
    "start_time = time.time()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "simulation_loss_results, human_loss_results, train_sequence_number,human_sequence_number, simulation_sequence_number, model = train_on_simulation_then_human_with_intermediate_tests(model,train_data_sim, train_data_human,val_data_sim,val_data_human,criterion,device,batch_size,n_simulation_sequences_train, n_human_sequences_train, n_sequences_test, gen_data_func, sim_lr = sim_lr, human_lr = human_lr, test_batch_increment_sim=test_batch_increment_sim, test_batch_increment_human=test_batch_increment_human)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0450ecdc-47cc-468d-9085-8fc6b58f6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_seq = 100\n",
    "model.eval()\n",
    "\n",
    "n_batches = int(np.round(n_total_seq / batch_size));\n",
    "\n",
    "loss_res = np.zeros((n_batches, 1), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d100d17-b115-426e-83e0-39cb34294dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [-0.1103,  0.7463,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463,  0.7463, -0.1103],\n",
       "        [ 0.7463, -0.1103,  0.7463],\n",
       "        [ 0.7463, -0.1103,  0.7463]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleChoiceOnly()\n",
    "\n",
    "test_data = test_data_human\n",
    "gen_batch_data = gen_data_func\n",
    "batch_idx = 3\n",
    "data, target = gen_batch_data(batch_size, batch_idx, test_data, use_human_data=use_human_data)\n",
    "data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "438dccaf-9702-415b-ba44-ce233b25e6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(data[:,0], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e32854d-d9b3-41b3-9298-c95af410ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output = nn.Linear(1,1)\n",
    "x = data\n",
    "o = torch.zeros(x.shape)\n",
    "for item in range(3):\n",
    "    a = torch.zeros(x.shape[0],1)\n",
    "    a[:,0] = x[:,0]\n",
    "    o[:,item] = torch.squeeze(input_output(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "798cd287-64ec-42f3-8e2d-931d9b9be86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5630, 0.7230, 0.7230, 0.7230, 0.5630, 0.5630, 0.7230, 0.5630, 0.7230,\n",
       "        0.5630, 0.7230, 0.7230, 0.7230, 0.7230, 0.5630, 0.7230, 0.7230, 0.5630,\n",
       "        0.7230, 0.7230, 0.7230, 0.7230, 0.5630, 0.7230, 0.7230, 0.7230, 0.7230,\n",
       "        0.7230, 0.7230, 0.7230, 0.7230, 0.7230], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(input_output(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a124e-ee4f-4642-af9d-78af3e7bffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        o = torch.zeros(x.shape)\n",
    "        for item in range(3):\n",
    "            o[:,item] = self.input_output(x[:,item].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1231daa5-874a-4fdf-9cce-e5e7ec0eeeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x[:,item],-1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9eb4c3f7-d5ac-4212-bba3-2ecba2c45c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5113b18a-fabb-4168-b53f-080a9ee647ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(x.shape[0],1)\n",
    "a[:,0] = x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5823917-2358-4d33-94b9-5d6b3c33bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1322],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [ 0.1322],\n",
       "        [ 0.1322],\n",
       "        [-0.4945],\n",
       "        [ 0.1322],\n",
       "        [-0.4945],\n",
       "        [ 0.1322],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [ 0.1322],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [ 0.1322],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [ 0.1322],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945],\n",
       "        [-0.4945]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_output(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56935e-7ae9-41c4-ae59-853a4a08c2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL [~/.conda/envs/pDL/]",
   "language": "python",
   "name": "conda_pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
