{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667fe701-921e-403b-b1d3-d4d5ced413c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'LSTM', 'train_seq_part': 'fix_and_choice', 'n_simulation_sequences_train': 0, 'n_human_sequences_train': 400000, 'n_sequences_test': 1000.0, 'n_sequences_final_performance': 1000.0, 'd_model': 128, 'n_layers': 2, 'n_head': 2, 'sim_lr': 0.001, 'human_lr': 0.001, 'batch_size': 32, 'run_idx': 0, 'on_cluster': True, 'test_batch_increment_sim': 500000.0, 'test_batch_increment_human': 100}\n",
      "<class 'numpy.int64'>\n",
      "Loading Data\n",
      "SimpleLSTM(\n",
      "  (lstm): LSTM(6, 128, batch_first=True)\n",
      "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "Training the model\n",
      "Training on simulated data\n",
      "Training on human data\n",
      "number of simulation seqeuences: 0number of human seqeuences: 3200 sim test loss: 5.667316359858359 human test loss 6.043567703616235\n",
      "number of simulation seqeuences: 0number of human seqeuences: 6400 sim test loss: 5.595686912536621 human test loss 5.97332109943513\n",
      "number of simulation seqeuences: 0number of human seqeuences: 9600 sim test loss: 5.486926886343187 human test loss 5.985050647489486\n",
      "number of simulation seqeuences: 0number of human seqeuences: 12800 sim test loss: 5.7549531998172885 human test loss 5.986518413789811\n",
      "number of simulation seqeuences: 0number of human seqeuences: 16000 sim test loss: 5.733965150771603 human test loss 5.927999988678963\n",
      "number of simulation seqeuences: 0number of human seqeuences: 19200 sim test loss: 5.527944141818631 human test loss 5.975775872507403\n",
      "number of simulation seqeuences: 0number of human seqeuences: 22400 sim test loss: 5.585389914051179 human test loss 5.958338768251481\n",
      "number of simulation seqeuences: 0number of human seqeuences: 25600 sim test loss: 5.495784244229717 human test loss 5.86701456193001\n",
      "number of simulation seqeuences: 0number of human seqeuences: 28800 sim test loss: 5.6263961176718436 human test loss 5.885290176637711\n",
      "number of simulation seqeuences: 0number of human seqeuences: 32000 sim test loss: 5.601009768824423 human test loss 5.828281218005765\n",
      "number of simulation seqeuences: 0number of human seqeuences: 35200 sim test loss: 5.422422047584288 human test loss 5.901160717010498\n",
      "number of simulation seqeuences: 0number of human seqeuences: 38400 sim test loss: 5.545499547835319 human test loss 5.868901160455519\n",
      "number of simulation seqeuences: 0number of human seqeuences: 41600 sim test loss: 5.5368959596080165 human test loss 5.812651987998716\n",
      "number of simulation seqeuences: 0number of human seqeuences: 44800 sim test loss: 5.518849765100787 human test loss 5.839284312340521\n",
      "number of simulation seqeuences: 0number of human seqeuences: 48000 sim test loss: 5.480311978247858 human test loss 5.800648104759954\n",
      "number of simulation seqeuences: 0number of human seqeuences: 51200 sim test loss: 5.376276469999744 human test loss 5.844101490512971\n",
      "number of simulation seqeuences: 0number of human seqeuences: 54400 sim test loss: 5.560956070500035 human test loss 5.819807467922088\n",
      "number of simulation seqeuences: 0number of human seqeuences: 57600 sim test loss: 5.574102909334244 human test loss 5.788851061174946\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/projects/RNNs/pref_master_file.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Call the function!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mmain_as_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_model_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_seq_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_seq_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_simulation_sequences_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_n_sim_seqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_human_sequences_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_n_human_seqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_run_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_lr_human\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_increment_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_increment_human\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# test human every 100 iters?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/RNNs/main_as_fun.py\u001b[0m in \u001b[0;36mmain_as_fun\u001b[0;34m(model_name, train_seq_part, n_simulation_sequences_train, n_human_sequences_train, n_sequences_test, n_sequences_final_performance, d_model, n_layers, n_head, sim_lr, human_lr, batch_size, run_idx, on_cluster, test_batch_increment_sim, test_batch_increment_human)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0msimulation_loss_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_loss_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sequence_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhuman_sequence_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulation_sequence_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_simulation_then_human_with_intermediate_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_human\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data_sim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data_human\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_simulation_sequences_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_human_sequences_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sequences_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_data_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuman_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_increment_sim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batch_increment_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_increment_human\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batch_increment_human\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# save results of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/RNNs/train_and_test_funs.py\u001b[0m in \u001b[0;36mtrain_on_simulation_then_human_with_intermediate_tests\u001b[0;34m(model, train_data_sim, train_data_human, test_data_sim, test_data_human, criterion, device, batch_size, n_simulation_sequences_train, n_human_sequences_train, n_sequences_test, gen_batch_data, sim_lr, human_lr, test_batch_increment_sim, test_batch_increment_human)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# update model, running a single batch on human data -- lol found the bug!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_batch_update_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_human\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_batch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_human_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mcurrent_batch_idx_human\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_batches_human\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepoch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/RNNs/train_and_test_funs.py\u001b[0m in \u001b[0;36mrun_batch_update_model\u001b[0;34m(model, train_data, gen_batch_data, batch_size, batch_idx, optimizer, criterion, device, use_human_data)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# Perform the forward pass of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# step 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# make sure target is correct type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pDL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/RNNs/neural_nets.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pDL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pDL/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run pref_master_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1b59bc-53c9-4c73-8740-f27483ecf467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_seq_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6814b-f7ca-43f8-87df-bea03002e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_human_epochs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e9582-81ac-40fe-80d5-f96637d09d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5e5/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f750b6-4f1e-4520-98f1-e1599215e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.75e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32402f94-cf61-4e42-a120-20f700c9431e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL [~/.conda/envs/pDL/]",
   "language": "python",
   "name": "conda_pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
