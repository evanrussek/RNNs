{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee9104a3-9ae0-41a2-b88f-294eb7bc4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up packages\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from res.sequential_tasks import pad_sequences, to_categorical\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5fb52d-ad03-49dc-8175-6187da827e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data files... \n",
    "sim_data_path = '/Users/evanrussek/Dropbox/Griffiths_Lab_Stuff/Data/RNNs/optimal_fixation_sims'\n",
    "human_data_path = '/Users/evanrussek/Dropbox/Griffiths_Lab_Stuff/Data/RNNs/human_trials.json'\n",
    "\n",
    "def load_data(sim_data_path, human_data_path, n_train=1e5, n_test=1e5):\n",
    "\n",
    "    train_file_idxs = range(1,16)\n",
    "    test_file_idxs = range(16,31)\n",
    "\n",
    "    train_files = [os.path.join(sim_data_path, str(i) + '.json') for i in train_file_idxs]\n",
    "    test_files = [os.path.join(sim_data_path, str(i) + '.json') for i in test_file_idxs]\n",
    "\n",
    "    a = [json.load(open(train_files[i])) for i in range(15)]\n",
    "    train_trials = [item for sublist in a for item in sublist]\n",
    "    del a\n",
    "    train_data_sim = train_trials[:int(1e6)]\n",
    "\n",
    "    test_trials = json.load(open(test_files[0]))\n",
    "    test_data_sim = test_trials[:int(1e5)]\n",
    "\n",
    "    human_data = json.load(open(human_data_path))\n",
    "    \n",
    "    return train_data_sim, test_data_sim, human_data\n",
    "\n",
    "train_data_sim, test_data_sim, human_data = load_data(sim_data_path, human_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9eb0563-65a8-4ce4-90da-c55ffaf0bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return type is a <class 'tuple'> with length 2.\n",
      "The first item in the tuple is the batch of sequences with shape (32, 139, 6).\n",
      "The first element in the batch of sequences is:\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "The second item in the tuple is the corresponding batch of targets with shape (32, 139, 3).\n",
      "The first element in the batch of targets is:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# this is for fixations and choice... \n",
    "def gen_batch_data_fixations_choice(batch_size, batch_idx, data, human_data=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Create sequence and target data for a batch\n",
    "\n",
    "    Input: \n",
    "        batch_size: number of trials to include in batch\n",
    "        batch_idx: index of data\n",
    "        data: list of dicts, where each dict has 'values', 'fixations', and 'choice'\n",
    "        human_data: this is just coded differently, so need to specify\n",
    "\n",
    "    Returns:\n",
    "        a tuple, (batch_data, batch_targets)\n",
    "        batch_data is 3d array: batch_size x sequence_size x one-hot categorical encoding (3 here)\n",
    "        batch_targets is 2d array: \n",
    "    \"\"\"\n",
    "\n",
    "    # filter list of trials that are in this batch\n",
    "    batch_sim_data = data[batch_idx*batch_size:((batch_idx+1)*(batch_size))]\n",
    "\n",
    "    # all sequences in the batch, attended item is coded as idx (as 0, 1, 2)\n",
    "    if human_data:\n",
    "        batch_fixation_sequences_idx = [(np.array(trial_data['fixations'])-1).tolist() for trial_data in batch_sim_data]\n",
    "    else:\n",
    "        batch_fixation_sequences_idx = [trial_data['fixations'] for trial_data in batch_sim_data]\n",
    "\n",
    "    batch_choices_idx = [trial_data['choice'] - 1 for trial_data in batch_sim_data]\n",
    "\n",
    "    # first 3 are fixation, last is choice...\n",
    "    batch_sequences_cat = [[to_categorical(x, num_classes = 6) for x in this_sequence] for this_sequence in batch_fixation_sequences_idx]\n",
    "\n",
    "    # now append to each of these the choice info - the choice gets it's own channel (of 3)\n",
    "    batch_sequences_cat_w_choices = [batch_sequences_cat[i] + [to_categorical(3 + batch_choices_idx[i], num_classes = 6)] for i in range(len(batch_sequences_cat))]\n",
    "    batch_data = pad_sequences(batch_sequences_cat_w_choices)\n",
    "    batch_data = batch_data.astype('float32')\n",
    "\n",
    "    batch_targets_init = np.array([trial_data['value'] for trial_data in batch_sim_data], dtype = 'float32')\n",
    "    batch_targets_cont = [np.repeat([batch_targets_init[i]],len(batch_sequences_cat_w_choices[i]),axis=0) for i in range(len(batch_sequences_cat_w_choices))]\n",
    "\n",
    "    batch_targets = pad_sequences(batch_targets_cont)\n",
    "    batch_targets = batch_targets.astype('float32')\n",
    "    \n",
    "    return (batch_data, batch_targets)\n",
    "\n",
    "example_batch = gen_batch_data_fixations_choice(32, 0, human_data,human_data=True) # batch size = 32, idx = 0\n",
    "print(f'The return type is a {type(example_batch)} with length {len(example_batch)}.')\n",
    "print(f'The first item in the tuple is the batch of sequences with shape {example_batch[0].shape}.')\n",
    "print(f'The first element in the batch of sequences is:\\n {example_batch[0][0, :, :]}')\n",
    "print(f'The second item in the tuple is the corresponding batch of targets with shape {example_batch[1].shape}.')\n",
    "print(f'The first element in the batch of targets is:\\n {example_batch[1][0, :]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed8bb27-6185-44cc-81f4-d9b14d57132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return type is a <class 'tuple'> with length 2.\n",
      "The first item in the tuple is the batch of choices with shape (32, 3).\n",
      "The first element in the batch of sequences is:\n",
      " [0. 0. 1.]\n",
      "The second item in the tuple is the corresponding batch of targets with shape (32, 3).\n",
      "The first element in the batch of targets is:\n",
      " [4. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# this is for just choice\n",
    "def gen_batch_data_choice_only(batch_size, batch_idx, data, human_data=False):\n",
    "    # filter list of trials that are in this batch\n",
    "    batch_sim_data = data[batch_idx*batch_size:((batch_idx+1)*(batch_size))]\n",
    "\n",
    "    # all sequences in the batch, attended item is coded as idx (as 0, 1, 2)\n",
    "    batch_choices_idx = [trial_data['choice'] - 1 for trial_data in batch_sim_data]\n",
    "\n",
    "    batch_data = to_categorical(batch_choices_idx)\n",
    "    batch_data = batch_data.astype('float32')\n",
    "\n",
    "    batch_targets = np.array([trial_data['value'] for trial_data in batch_sim_data], dtype = 'float32')\n",
    "    batch_targets= batch_targets.astype('float32')\n",
    "    return (batch_data, batch_targets)\n",
    "\n",
    "example_batch = gen_batch_data_choice_only(32, 0, human_data,human_data=True) # batch size = 32, idx = 0\n",
    "print(f'The return type is a {type(example_batch)} with length {len(example_batch)}.')\n",
    "print(f'The first item in the tuple is the batch of choices with shape {example_batch[0].shape}.')\n",
    "print(f'The first element in the batch of sequences is:\\n {example_batch[0][0, :]}')\n",
    "print(f'The second item in the tuple is the corresponding batch of targets with shape {example_batch[1].shape}.')\n",
    "print(f'The first element in the batch of targets is:\\n {example_batch[1][0, :]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ba085a8-97f6-44e4-a105-3a4d72e200e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return type is a <class 'tuple'> with length 2.\n",
      "The first item in the tuple is the batch of sequences with shape (32, 138, 3).\n",
      "The first element in the batch of sequences is:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "The second item in the tuple is the corresponding batch of targets with shape (32, 138, 3).\n",
      "The first element in the batch of targets is:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]\n",
      " [4. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# this is for fixations only\n",
    "def gen_batch_data_fixations_only(batch_size, batch_idx, data, human_data=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Create sequence and target data for a batch\n",
    "\n",
    "    Input: \n",
    "        batch_size: number of trials to include in batch\n",
    "        batch_idx: index of data\n",
    "        data: list of dicts, where each dict has 'values', 'fixations', and 'choice'\n",
    "        human_data: this is just coded differently, so need to specify\n",
    "\n",
    "    Returns:\n",
    "        a tuple, (batch_data, batch_targets)\n",
    "        batch_data is 3d array: batch_size x sequence_size x one-hot categorical encoding (3 here)\n",
    "        batch_targets is 2d array: \n",
    "    \"\"\"\n",
    "\n",
    "    # filter list of trials that are in this batch\n",
    "    batch_sim_data = data[batch_idx*batch_size:((batch_idx+1)*(batch_size))]\n",
    "\n",
    "    # all sequences in the batch, attended item is coded as idx (as 0, 1, 2)\n",
    "    if human_data:\n",
    "        batch_fixation_sequences_idx = [(np.array(trial_data['fixations'])-1).tolist() for trial_data in batch_sim_data]\n",
    "    else:\n",
    "        batch_fixation_sequences_idx = [trial_data['fixations'] for trial_data in batch_sim_data]\n",
    "\n",
    "    # first 3 are fixation, last is choice...\n",
    "    batch_sequences_cat = [[to_categorical(x, num_classes = 3) for x in this_sequence] for this_sequence in batch_fixation_sequences_idx]\n",
    "\n",
    "    # now append to each of these the choice info - the choice gets it's own channel (of 3)\n",
    "    batch_data = pad_sequences(batch_sequences_cat)\n",
    "    batch_data = batch_data.astype('float32')\n",
    "\n",
    "    batch_targets_init = np.array([trial_data['value'] for trial_data in batch_sim_data], dtype = 'float32')\n",
    "    batch_targets_cont = [np.repeat([batch_targets_init[i]],len(batch_sequences_cat[i]),axis=0) for i in range(len(batch_sequences_cat))]\n",
    "\n",
    "    batch_targets = pad_sequences(batch_targets_cont)\n",
    "    batch_targets = batch_targets.astype('float32')\n",
    "    \n",
    "    return (batch_data, batch_targets)\n",
    "\n",
    "example_batch = gen_batch_data_fixations_only(32, 0, human_data,human_data=True) # batch size = 32, idx = 0\n",
    "print(f'The return type is a {type(example_batch)} with length {len(example_batch)}.')\n",
    "print(f'The first item in the tuple is the batch of sequences with shape {example_batch[0].shape}.')\n",
    "print(f'The first element in the batch of sequences is:\\n {example_batch[0][0, :, :]}')\n",
    "print(f'The second item in the tuple is the corresponding batch of targets with shape {example_batch[1].shape}.')\n",
    "print(f'The first element in the batch of targets is:\\n {example_batch[1][0, :]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7e19b47-151a-438f-a725-5c969222d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set up neural networks\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.lstm(x)[0]\n",
    "        x = self.linear(h)\n",
    "        return x\n",
    "    \n",
    "    def get_states_across_time(self, x):\n",
    "        h_c = None\n",
    "        h_list, c_list = list(), list()\n",
    "        with torch.no_grad():\n",
    "            for t in range(x.size(1)):\n",
    "                h_c = self.lstm(x[:, [t], :], h_c)[1]\n",
    "                h_list.append(h_c[0])\n",
    "                c_list.append(h_c[1])\n",
    "            h = torch.cat(h_list)\n",
    "            c = torch.cat(c_list)\n",
    "        return h, c\n",
    "    \n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_output = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        ha = self.input_hidden(x)\n",
    "        hb = F.relu(ha)\n",
    "        o = self.hidden_output(hb)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d3202d7-fb5f-4695-8986-12caa6743786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_sim_data, criterion, device, batch_size, n_total_seq, gen_batch_data):\n",
    "    # Set the model to evaluation mode. This will turn off layers that would\n",
    "    # otherwise behave differently during training, such as dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    n_total_seq = 50000\n",
    "\n",
    "    n_batches = int(np.round(n_total_seq / batch_size));\n",
    "\n",
    "    loss_res = np.zeros((n_batches, 1), dtype=float)\n",
    "\n",
    "    # A context manager is used to disable gradient calculations during inference\n",
    "    # to reduce memory usage, as we typically don't need the gradients at this point.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(n_batches):\n",
    "            data, target = gen_batch_data(batch_size, batch_idx, test_sim_data)\n",
    "            data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            to_keep = target != 0\n",
    "            target = target[to_keep]\n",
    "            output = output[to_keep]\n",
    "            \n",
    "            \n",
    "            # Pick only the output corresponding to last sequence element (input is pre padded)\n",
    "            # output = output[:, -1, :]\n",
    "\n",
    "            # target = target.argmax(dim=1)\n",
    "            loss = criterion(output, target)  # is this just for the last batch?\n",
    "\n",
    "            # store the loss\n",
    "            loss_res[batch_idx] = loss.item()\n",
    "\n",
    "    return np.mean(loss_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12d9f6b5-c2bb-4e74-8c93-4adf8be9093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, train_sim_data, test_sim_data, criterion, optimizer, device, batch_size, n_total_seq, gen_batch_data, make_plot = False, model_name = \"\"):\n",
    "    # Set the model to training mode. This will turn on layers that would\n",
    "    # otherwise behave differently during evaluation, such as dropout.\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    # how many batches\n",
    "    n_batches = int(np.round(n_total_seq/batch_size));\n",
    "    for batch_idx in range(n_batches):\n",
    "\n",
    "        # Request a batch of sequences and class labels, convert them into tensors\n",
    "        # of the correct type, and then send them to the appropriate device.\n",
    "        #data, target = train_data_gen[batch_idx] # just alter this to the function that produces the data?\n",
    "        data, target = gen_batch_data(batch_size, batch_idx, train_sim_data)\n",
    "        \n",
    "        # this needs to change... \n",
    "        data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
    "\n",
    "        # Perform the forward pass of the model\n",
    "        output = model(data)  # Step ①\n",
    "\n",
    "        \n",
    "        # for some reason target is an int, and dosn't match the output which is float32\n",
    "        target = target.to(torch.float32)\n",
    "        \n",
    "        # remove padding (nicely, this is just 0's)\n",
    "        to_keep = target != 0\n",
    "        target = target[to_keep]\n",
    "        output = output[to_keep]\n",
    "        \n",
    "        # need to re-write this function... \n",
    "        loss = criterion(output, target)  # Step ②\n",
    "\n",
    "        # Clear the gradient buffers of the optimized parameters.\n",
    "        # Otherwise, gradients from the previous batch would be accumulated.\n",
    "        optimizer.zero_grad()  # Step ③\n",
    "\n",
    "        loss.backward()  # Step ④\n",
    "\n",
    "        optimizer.step()  # Step ⑤\n",
    "        \n",
    "    # compute the test loss... \n",
    "    test_loss = test(model, test_data_sim, criterion, device, batch_size, n_total_seq, gen_batch_data)\n",
    "\n",
    "    return model, test_loss#loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2e22310-02f0-4ca0-bebf-d349cc5892fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "--- 72.00483918190002 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Setup the training and test data generators\n",
    "batch_size     = 32\n",
    "n_total_seq = 1e5\n",
    "n_batches = int(np.round(n_total_seq/batch_size));\n",
    "\n",
    "n_runs = 1\n",
    "LSTM_run_losses = np.zeros((n_runs, n_tests))\n",
    "for run_idx in range(n_runs):\n",
    "    torch.manual_seed(run_idx)\n",
    "\n",
    "    print(run_idx)\n",
    "\n",
    "    # Setup the RNN and training settings\n",
    "    input_size  = 6 # this is the length of the input vector? #train_data_gen.n_symbols\n",
    "    hidden_size = 50\n",
    "    output_size = 3 # this is the leågth of the output vector #train_data_gen.n_classes\n",
    "    model       = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "    criterion   = torch.nn.MSELoss() # torch.nn.CrossEntropyLoss()\n",
    "    optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    # optimizer   = torch.optim.Adam(model.parameters(), lr=0.00304)\n",
    "    max_epochs  = 10\n",
    "    device = torch.device('cpu')#torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    data_func = gen_batch_data_fixations_choice\n",
    "\n",
    "    # Train the model›\n",
    "    # model = train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs)\n",
    "    start_time = time.time()\n",
    "    # model_LSTM = train_and_test(model, train_data_sim, test_data_sim, criterion, optimizer, max_epochs, batch_size, n_total_seq, verbose=True, model_name = 'LSTM')\n",
    "    device = torch.device('cpu')#torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model_LSTM, LSTM_loss = train_and_test(model, train_data_sim, test_data_sim, criterion, optimizer, device, batch_size, n_total_seq, data_func, model_name='LSTM')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71245593-b709-4a2c-a2f3-46722ab80d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.048254382595057"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98e067-8726-46bf-8eea-3b44d2639b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
