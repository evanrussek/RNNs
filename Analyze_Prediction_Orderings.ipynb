{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dea7a8-734c-427a-8105-bc7deb3714ae",
   "metadata": {},
   "source": [
    "## Load trained models, and take new metric of test performance - how often correct max or mins are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd900d96-2678-4d52-90c9-d87d076bbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# funcs stolen from nyu deep learning course\n",
    "from sequential_tasks import pad_sequences, to_categorical\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from load_data_funs import load_data, gen_batch_data_fixations_choice, gen_batch_data_fixations_only, gen_batch_data_choice_only\n",
    "\n",
    "on_cluster=True\n",
    "if on_cluster:\n",
    "    sim_data_path = '/scratch/gpfs/erussek/RNN_project/optimal_fixation_sims'\n",
    "    human_data_path = '/scratch/gpfs/erussek/RNN_project/human_trials.json'\n",
    "else:\n",
    "    sim_data_path = '/Users/evanrussek/Dropbox/Griffiths_Lab_Stuff/Data/RNNs/optimal_fixation_sims'\n",
    "    human_data_path = '/Users/evanrussek/Dropbox/Griffiths_Lab_Stuff/Data/RNNs/human_trials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb4a668-b23a-4b99-91cd-f8af796d6d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load data train and test sets...\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data_sim, test_data_sim, human_data \u001b[38;5;241m=\u001b[39m load_data(sim_data_path, human_data_path, this_seed\u001b[38;5;241m=\u001b[39m\u001b[43mjob_idx\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'job_idx' is not defined"
     ]
    }
   ],
   "source": [
    "# load data train and test sets...\n",
    "train_data_sim, test_data_sim, human_data = load_data(sim_data_path, human_data_path, this_seed=job_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1d871-27ec-4bc3-b2aa-5a1958b4e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compoute correlation with held-out test data... \n",
    "def test_record_each_output(model, test_sim_data, device, batch_size, n_total_seq, gen_batch_data,out_idx, choice_only=False, human_data=False):\n",
    "    # Set the model to evaluation mode. This will turn off layers that would\n",
    "    # otherwise behave differently during training, such as dropout.\n",
    "    \n",
    "    # print(choice_only)\n",
    "    model.eval()\n",
    "\n",
    "    # Store the number of sequences that were classified correctly\n",
    "    # num_correct = 0\n",
    "\n",
    "    n_batches = int(np.round(n_total_seq/batch_size));\n",
    "\n",
    "    output_all = np.zeros((0,3))\n",
    "    target_all = np.zeros((0,3))\n",
    "\n",
    "    # A context manager is used to disable gradient calculations during inference\n",
    "    # to reduce memory usage, as we typically don't need the gradients at this point.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(n_batches):\n",
    "            data, target = gen_batch_data(batch_size, batch_idx, test_sim_data, human_data = human_data)\n",
    "            data, target = torch.from_numpy(data).float().to(device), torch.from_numpy(target).long().to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            # Pick only the output corresponding to last sequence element (input is pre padded)\n",
    "            if not choice_only:\n",
    "                output = output[:, -out_idx, :]\n",
    "                target = target[:,-out_idx,:]\n",
    "\n",
    "            output_all = np.concatenate((output_all, output.numpy()))\n",
    "            target_all = np.concatenate((target_all, target.numpy()))\n",
    "\n",
    "    return (output_all, target_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364ca79-dc9d-4edc-a8a3-c63e5486e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(to_save_folder, train_setting, job_idx):\n",
    "    \n",
    "    model_full_file_name = os.path.join(to_save_folder, 'model_train_setting_{}_job_{}'.format(train_setting,job_idx))\n",
    "    trained_model = torch.load(model_full_file_name)\n",
    "\n",
    "    return trained_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb183885-7910-4dfa-891c-a060c8afa774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_setting=0\n",
    "job_idx=0\n",
    "\n",
    "on_cluster = True\n",
    "# set up folder to save results\n",
    "if on_cluster:\n",
    "    to_save_folder = '/scratch/gpfs/erussek/RNN_project/train_on_sim_results'\n",
    "else:\n",
    "    to_save_folder = '/Users/evanrussek/Dropbox/Griffiths_Lab_Stuff/Code/RNNs/train_on_sim_results'\n",
    "\n",
    "def get_pct_max_min(trained_model, test_data_sim, train_setting, n_back):\n",
    "\n",
    "    train_data_funcs = [gen_batch_data_fixations_choice, gen_batch_data_fixations_only, gen_batch_data_choice_only]\n",
    "    this_data_func = train_data_funcs[train_setting]\n",
    "\n",
    "    # train on a 1 mil. examples, generate learning curves... \n",
    "    batch_size  = 32\n",
    "    n_total_seq = 1.5e6\n",
    "    n_batches = int(np.round(n_total_seq/batch_size));\n",
    "    n_tests = int(np.ceil(n_batches/200)) - 1\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    n_seq_test = 1000\n",
    "    \n",
    "    choice_only=False\n",
    "    if train_setting==2:\n",
    "        choice_only=True\n",
    "        \n",
    "    output_all_LSTM, target_all_LSTM = test_record_each_output(trained_model, test_data_sim, device, batch_size, n_seq_test,this_data_func, n_back,choice_only=choice_only, human_data=human_data)\n",
    "\n",
    "    output_max_item = output_all_LSTM.argmax(axis=1)\n",
    "    target_max_item = target_all_LSTM.argmax(axis=1)\n",
    "    pct_correct_max = np.sum(output_max_item == target_max_item)/len(output_max_item)\n",
    "\n",
    "    output_min_item = output_all_LSTM.argmin(axis=1)\n",
    "    target_min_item = target_all_LSTM.argmin(axis=1)\n",
    "    \n",
    "    print(output_min_item)\n",
    "    \n",
    "    pct_correct_min = np.sum(output_min_item == target_min_item)/len(output_min_item)\n",
    "    \n",
    "    return pct_correct_max, pct_correct_min\n",
    "\n",
    "\n",
    "get_pct_max_min(trained_model, test_data_sim, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de325361-70db-49a4-9a70-080ffc20b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_get_pct_max_min(to_save_folder, train_setting, job_idx, n_back=1):\n",
    "    trained_model = load_model(to_save_folder, train_setting, job_idx)\n",
    "    return get_pct_max_min(trained_model, test_data_sim, train_setting, n_back)\n",
    "\n",
    "\n",
    "all_jobs = np.arange(50)\n",
    "if train_setting < 2:\n",
    "    bad_jobs = []\n",
    "else:\n",
    "    bad_jobs = [1,10]\n",
    "\n",
    "good_jobs = np.delete(all_jobs,bad_jobs);\n",
    "\n",
    "n_jobs = len(good_jobs)\n",
    "max_min_res0 = np.zeros((len(good_jobs),2))\n",
    "max_min_res1 = np.zeros((len(good_jobs),2))\n",
    "max_min_res2 = np.zeros((len(good_jobs),2))\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    print(i, end=' ')\n",
    "    max_min_res0[i,:] = load_model_and_get_pct_max_min(to_save_folder, 0, good_jobs[i], n_back=1)  \n",
    "    #max_min_res1[i,:] = load_model_and_get_pct_max_min(to_save_folder, 1, good_jobs[i], n_back=1)\n",
    "    #max_min_res2[i,:] = load_model_and_get_pct_max_min(to_save_folder, 2, good_jobs[i], n_back=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd3a26-e7a0-4046-9afa-e8f6a419ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(max_min_res1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7b5d5d0-c450-4287-aead-ae42a4242df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72983871, 0.49431452])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(max_min_res2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f86cb-97b8-446b-a274-18600fa86d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
